{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importamos las librerías que necesitamos\n",
    "\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluar linealidad de las relaciones entre las variables\n",
    "# y la distribución de las variables\n",
    "# ------------------------------------------------------------------------------\n",
    "#import scipy.stats as stats\n",
    "# from scipy.stats import shapiro, ktest,  poisson, chisquare, expon, kstest\n",
    "from scipy.stats import shapiro, kstest, poisson, chisquare, expon\n",
    "\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "\n",
    "# Gestión de los warnings\n",
    "# -----------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios estadística inferencial\n",
    "\n",
    "1. Igual que en los ejercicios de la clase invertida, evalúa si las siguientes afirmaciones corresponden a una distribución exponencial o poisson.\n",
    "\n",
    "¿El tiempo que transcurre entre la llegada de autobuses a una parada sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El número de errores en un artículo de noticias sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El tiempo que transcurre entre la llegada de solicitudes de servicio en un restaurante sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El número de accidentes de tráfico en una hora en una ciudad sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El tiempo entre llegadas de llamadas telefónicas a una central de emergencias sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El número de clientes que ingresan a una tienda en una hora sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El tiempo entre llegadas de correos electrónicos en una bandeja de entrada sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El número de defectos en una línea de producción por día sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El tiempo que transcurre entre la llegada de taxis en una parada sigue una distribución exponencial o de Poisson?\n",
    "\n",
    "¿El número de errores de ortografía en un libro de texto sigue una distribución exponencial o de Poisson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ejercicios intervalo de confianza. Al igual que en el caso del ejercicio de la clase invertida, piensa un motivo por el que sería interesante calcular estos intervalos de confianza para la extracción de insights.\n",
    "\n",
    "Intervalo de Confianza para la Esperanza de Vida\n",
    "\n",
    "Contexto: Trabajas en una organización de salud global y deseas estimar el intervalo de confianza al 95% para la esperanza de vida promedio de cada continente.\n",
    "\n",
    "Nota: Cuidado porque puede que os salgan algunos nulos, genera un código para que no salgan nulos en los intervalos de confianza.\n",
    "\n",
    "Intervalo de Confianza para el PIB\n",
    "\n",
    "Contexto: Eres una economista y quieres calcular el intervalo de confianza al 90% para el Producto Interno Bruto (PIB) de los continentes.\n",
    "\n",
    "Intervalo de Confianza para la Tasa de Natalidad\n",
    "\n",
    "Contexto: Trabajas en una agencia gubernamental que se ocupa de cuestiones demográficas y deseas determinar el intervalo de confianza al 99% para la tasa de natalidad promedio en Asia.\n",
    "\n",
    "Intervalo de Confianza para la Tasa de Desempleo\n",
    "\n",
    "Contexto: Eres un analista de políticas públicas y deseas calcular el intervalo de confianza al 95% para la tasa de desempleo promedio en los países de Oceanía.\n",
    "\n",
    "Intervalo de Confianza para la Tasa de Impuestos\n",
    "\n",
    "Contexto: Trabajas en un ministerio de finanzas y deseas estimar el intervalo de confianza al 90% para la tasa de impuestos promedio en los países de África."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Ejercicios prueba de hipótesis: Hasta ahora en la lección y en los ejercicios de la clase invertida os hemos propuesto un contexto y unas hipótesis para entender que es la prueba de hipótesis. Ahora es tu turno, tienes que pensar en 2 hipótesis que quieras aceptar o rechazar usando una prueba de hipótesis en base a los datos que tenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAMOS DT ALEATORIO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos aleatorios que sigan una distribución normal\n",
    "np.random.seed(0)\n",
    "\n",
    "# generamos un array con media = 0, desviación estándar = 1, 1000 muestras\n",
    "data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "# creamos un DataFrame con los datos normales creados previamente\n",
    "df_normal = pd.DataFrame({'Datos': data})\n",
    "\n",
    "# Crear un histograma para visualizar la distribución\n",
    "plt.hist(df_normal['Datos'], \n",
    "         bins=30, \n",
    "         density=True, \n",
    "         alpha=0.5)\n",
    "\n",
    "# ponemos título a la gráfica\n",
    "plt.title('Histograma de Datos')\n",
    "\n",
    "# cambiamos el nombre del eje x\n",
    "plt.xlabel('Valor')\n",
    "\n",
    "# cambiamos el nombre del eje y\n",
    "plt.ylabel('Frecuencia');\n",
    "\n",
    "# como podemos ver los datos generados tienen forma de campana de Gaus, por lo que podemos decir que es una distribución normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SHAPIRO KOLMO DIST NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una prueba de normalidad (usando la prueba de Shapiro-Wilk)\n",
    "p_value = shapiro(df_normal['Datos']).pvalue\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print(\"Los datos se ajustan a una distribución normal (p-value =\", p_value, \")\")\n",
    "else:\n",
    "    print(\"Los datos no se ajustan a una distribución normal (p-value =\", p_value, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una prueba de normalidad (usando la prueba de Kolmogorov)\n",
    "p_value = kstest(df_normal['Datos'], \"norm\").pvalue\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print(\"Los datos se ajustan a una distribución normal (p-value =\", p_value, \")\")\n",
    "else:\n",
    "    print(\"Los datos no se ajustan a una distribución normal (p-value =\", p_value, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAMOS DISTRIBUCION UNIFORME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una matriz de 3x3 de números aleatorios entre -1 y 1\n",
    "matriz_uniforme = np.random.uniform(0, 1, size=10000)\n",
    "\n",
    "# creamos un DataFrame con los datos normales creados previamente\n",
    "df_uniforme = pd.DataFrame({'Datos': matriz_uniforme})\n",
    "\n",
    "# Crear un histograma para visualizar la distribución\n",
    "plt.hist(df_uniforme['Datos'], \n",
    "         bins=30, \n",
    "         density=True, \n",
    "         alpha=0.5)\n",
    "\n",
    "# ponemos título a la gráfica\n",
    "plt.title('Histograma de Datos')\n",
    "\n",
    "# cambiamos el nombre del eje x\n",
    "plt.xlabel('Valor')\n",
    "\n",
    "# cambiamos el nombre del eje y\n",
    "plt.ylabel('Frecuencia');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAMOS POISSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar 1000 números aleatorios con distribución de Poisson con lambda=2.0\n",
    "lambda_ = 3  # Parámetro lambda (μ) de la distribución de Poisson\n",
    "data = np.random.poisson(lam=lambda_, size=100)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las frecuencias observadas\n",
    "valores_unicos, frec_observada = np.unique(data, return_counts=True)\n",
    "\n",
    "# Calcular las frecuencias esperadas para una distribución de Poisson\n",
    "frec_esperada = poisson.pmf(k = valores_unicos, mu=lambda_) * len(data)\n",
    "\n",
    "# Normalizar las frecuencias esperadas y observadas para que sumen lo mismo\n",
    "frec_esperada = frec_esperada * (np.sum(frec_observada) / np.sum(frec_esperada))\n",
    "\n",
    "# Realizar la prueba de chi-cuadrado para verificar el ajuste a la distribución de Poisson\n",
    "statistic, p_value = chisquare(f_obs=frec_observada, f_exp=frec_esperada)\n",
    "\n",
    "# Interpretar los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "print(f'Estadística de prueba Chi-cuadrado: {statistic}, Valor p: {p_value}')\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Los datos siguen una distribución de Poisson (no se rechaza la hipótesis nula)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución de Poisson (se rechaza la hipótesis nula)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAMOS EXPONENCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetro de tasa lambda (también conocido como tasa de eventos)\n",
    "lambda_param = 0.5  # Puedes ajustar este valor según tus necesidades\n",
    "\n",
    "# generamos números aleatorios distribuidos exponencialmente\n",
    "datos_exponenciales = np.random.exponential(scale=1/lambda_param, size=1000)\n",
    "datos_exponenciales[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de los datos a una distribución exponencial\n",
    "loc, scale = expon.fit(datos_exponenciales)\n",
    "\n",
    "# Prueba estadística para verificar el ajuste a la distribución exponencial\n",
    "statistic, p_value = kstest(datos_exponenciales, 'expon', args=(loc, scale))\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "print(f'Estadística de prueba KS: {statistic}, Valor p: {p_value}')\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Los datos siguen una distribución exponencial (no se rechaza la hipótesis nula)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución exponencial (se rechaza la hipótesis nula)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalo de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es calcular la estimación puntual, en este caso calcularemos la media de la duración de las llamadas\n",
    "media_duracion = df[\"duration\"].mean()\n",
    "\n",
    "\n",
    "# después vamos a calcular el error estándar utilizando el método \"sem\" de la librería stats\n",
    "error_duracion = stats.sem(df[\"duration\"])\n",
    "\n",
    "# definimos el nivel de confianza (95% en este caso)\n",
    "nivel_confianza_duracion = 0.95\n",
    "\n",
    "# calculamos los grados de libertad de la muestra. Recordad que debemos restar el total de datos que tenemos -1. \n",
    "grados_libertad_duracion = len(df[\"duration\"]) - 1\n",
    "\n",
    "# calculamos el valor crítico de la muestra\n",
    "valor_critico_duracion = stats.t.ppf((1 + nivel_confianza_duracion) / 2, df=grados_libertad_duracion)\n",
    "\n",
    "# calculamos el intervalo de confianza\n",
    "limite_inferior_duracion = media_duracion - valor_critico_duracion * error_duracion\n",
    "limite_superior_duracion = media_duracion + valor_critico_duracion * error_duracion\n",
    "\n",
    "print(\"Intervalo de Confianza para la Duración de Llamadas Telefónicas:\")\n",
    "print(f\"Media Muestral: {np.round(media_duracion, 2)}\")\n",
    "print(f\"Error Estándar: {np.round(error_duracion, 2)}\")\n",
    "print(f\"Nivel de Confianza: {nivel_confianza_duracion}\")\n",
    "print(f\"Valor Crítico: {np.round(valor_critico_duracion, 2)}\")\n",
    "print(f\"Intervalo de Confianza: ({np.round(limite_inferior_duracion, 2)}, {np.round(limite_superior_duracion, 2)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de hipótesis STUDEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a definir una función para poder hacer el t-test de Student\n",
    "\n",
    "def prueba_hipotesis(*args):\n",
    "    \n",
    "    # lo primero que tenemos que hacer es mirar si las varianzas son iguales o no\n",
    "    if len(args) == 2:\n",
    "        p_valor_varianza = stats.levene(*args, center = \"median\")[1]\n",
    "    else:\n",
    "        p_valor_varianza = stats.bartlett(*args)[1]\n",
    "    \n",
    "    if p_valor_varianza > 0.05:\n",
    "        # realizamos la prueba t de Student\n",
    "        t_stat, p_valor = stats.ttest_ind(*args, equal_var=True)\n",
    "    else:\n",
    "        t_stat, p_valor = stats.ttest_ind(*args, equal_var=False)\n",
    "        \n",
    "    # Establecemos un nivel de significancia (alfa)\n",
    "    alfa = 0.05\n",
    "\n",
    "    # comparamos el p-valor con el nivel de significancia\n",
    "    if p_valor < alfa:\n",
    "        print(\"Rechazamos la hipótesis nula.\")\n",
    "        print(\"Hay una diferencia significativa en los ingresos promedio entre los dos grupos.\")\n",
    "    else:\n",
    "        print(\"No podemos rechazar la hipótesis nula.\")\n",
    "        print(\"No hay evidencia suficiente para afirmar una diferencia significativa en los ingresos promedio entre los dos grupos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtramos los datos para obtener dos grupos: educación básica 4 años y educación secundaria\n",
    "grupo_educacion_basica = df[df['education'] == 'basic 4y'][\"income\"]\n",
    "grupo_educacion_secundaria = df[df['education'] == 'high school'][\"income\"]\n",
    "\n",
    "# llamamos a la función que hemos creado\n",
    "prueba_hipotesis(grupo_educacion_basica, grupo_educacion_secundaria )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../files/test_group.csv\", sep = \";\")\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
