{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importamos las librerías que necesitamos\n",
    "\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluar linealidad de las relaciones entre las variables\n",
    "# y la distribución de las variables\n",
    "# ------------------------------------------------------------------------------\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "\n",
    "# Gestión de los warnings\n",
    "# -----------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats import chi2_contingency, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = pd.read_csv(\"marketing_AB.csv\", sep =\";\")\n",
    "df_control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 1:\n",
    "Supongamos que estamos realizando un experimento para determinar si un nuevo diseño de anuncio (test group \"ad\") tiene un impacto significativo en la tasa de conversión en comparación con el diseño de anuncio anterior (test group \"psa\").\n",
    "\n",
    "Objetivo del ejercicio: Comparar las tasas de conversión entre los grupos de prueba \"ad\" y \"psa\" para determinar si el nuevo diseño de anuncio es más efectivo en la conversión de usuarios.\n",
    "\n",
    "Pasos que debemos seguir:\n",
    "\n",
    "Preparación de los datos: Asegúrate de que los datos estén limpios y listos para el análisis. Esto incluye la eliminación de datos faltantes y la verificación de la coherencia de los datos.\n",
    "\n",
    "Definición de las hipótesis: Plantea una hipótesis nula (H0) y una hipótesis alternativa (H1) para el experimento (en este caso os las damos definidas):\n",
    "\n",
    "Hipótesis nula (H0): No hay diferencia significativa en la tasa de conversión entre los grupos de prueba \"ad\" y \"psa\".\n",
    "\n",
    "Hipótesis alternativa (H1): Existe una diferencia significativa en la tasa de conversión entre los grupos de prueba \"ad\" y \"psa\".\n",
    "\n",
    "Cálculo de la tasa de conversión: Calcula la tasa de conversión para cada grupo:\n",
    "\n",
    "Para el grupo \"ad\", la tasa de conversión es el número de usuarios convertidos dividido por el número total de usuarios en ese grupo.\n",
    "\n",
    "Para el grupo \"psa\", realiza el mismo cálculo.\n",
    "\n",
    "Prueba de hipótesis: Utiliza una prueba estadística, como la prueba t de Student o la prueba chi-cuadrado, para comparar las tasas de conversión entre los grupos \"ad\" y \"psa\".\n",
    "\n",
    "Análisis de resultados:\n",
    "\n",
    "Si el valor p es menor que un umbral predefinido (por ejemplo, 0.05), rechazamos la hipótesis nula y concluimos que hay una diferencia significativa en las tasas de conversión entre los grupos.\n",
    "\n",
    "Si el valor p es mayor que el umbral, no podemos rechazar la hipótesis nula y concluimos que no hay evidencia suficiente para afirmar que hay una diferencia significativa.\n",
    "\n",
    "Conclusiones y recomendaciones: Basándote en los resultados de la prueba de hipótesis, llega a una conclusión sobre si el nuevo diseño de anuncio es más efectivo en la conversión de usuarios que el diseño anterior. Si es así, puedes hacer recomendaciones basadas en estos hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "En este caso, vamos a realizar un experimento para comparar la cantidad promedio de anuncios vistos por los usuarios en los grupos \"ad\" y \"psa\" y determinar si hay una diferencia significativa entre ellos.\n",
    "\n",
    "Objetivo del experimento: Comparar la cantidad promedio de anuncios vistos por usuario entre los grupos de prueba \"ad\" y \"psa\" para determinar si el tipo de anuncio afecta la cantidad de anuncios que los usuarios ven.\n",
    "\n",
    "Preparación de los datos: Asegúrate de que los datos estén limpios y listos para el análisis. Esto incluye la eliminación de datos faltantes y la verificación de la coherencia de los datos.\n",
    "\n",
    "Hipótesis: Plantea una hipótesis nula (H0) y una hipótesis alternativa (H1) para el experimento. En este caso, las deberéis plantear vosotras\n",
    "\n",
    "Prueba de hipótesis: Utiliza una prueba estadística, como la prueba t de Student, para comparar la cantidad promedio de anuncios vistos por usuario entre los grupos \"ad\" y \"psa\". Esto te permitirá determinar si hay una diferencia significativa entre los dos grupos.\n",
    "\n",
    "Análisis de resultados:\n",
    "\n",
    "Si el valor p (p-value) es menor que un umbral predefinido (por ejemplo, 0.05), rechazamos la hipótesis nula y concluimos que hay una diferencia significativa en la cantidad promedio de anuncios vistos por usuario entre los grupos.\n",
    "\n",
    "Si el valor p es mayor que el umbral, no podemos rechazar la hipótesis nula y concluimos que no hay evidencia suficiente para afirmar que hay una diferencia significativa.\n",
    "\n",
    "Conclusiones y recomendaciones: Basándote en los resultados de la prueba de hipótesis, llega a una conclusión sobre si el tipo de anuncio (ad o psa) tiene un impacto significativo en la cantidad promedio de anuncios vistos por usuario. Si es así, puedes hacer recomendaciones basadas en estos hallazgos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que vamos a hacer es unir los dos DataFrames en uno solo para no tener que estar haciendo todo el trabajo por duplicado\n",
    "df = pd.concat([df_control, df_test], axis = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a cambiar el nombre de las columnas para que no tengan nombres tan extraños\n",
    "columnas = [col.lower().split(\"[\")[0].replace(\"#\", \"\").strip().replace(\" \", \"_\") for col in df.columns]\n",
    "df.columns = columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la Tasa de Clics\n",
    "df['CTR'] = df['of_website_clicks'] / df['of_impressions']\n",
    "\n",
    "# calculamos la Tasa de Conversión\n",
    "df['CR'] = df['of_purchase'] / df['of_website_clicks']\n",
    "\n",
    "# calculamos el Coste por Adquisición\n",
    "df['CPA'] = df['spend'] / df['of_purchase']\n",
    "\n",
    "# mostramos el DataFrame para confirmar que todo ha ido bien. \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez que tengamos nuestro DataFrame preparado con todas las columnas que queremos vamos a crear una función que no haga una exploración inicial del conjunto de datos\n",
    "def exploracion_dataframe(dataframe, columna_control):\n",
    "    \"\"\"\n",
    "    Realiza un análisis exploratorio básico de un DataFrame, mostrando información sobre duplicados,\n",
    "    valores nulos, tipos de datos, valores únicos para columnas categóricas y estadísticas descriptivas\n",
    "    para columnas categóricas y numéricas, agrupadas por la columna de control.\n",
    "\n",
    "    Parámetros:\n",
    "    - dataframe (DataFrame): El DataFrame que se va a explorar.\n",
    "    - columna_control (str): El nombre de la columna que se utilizará como control para dividir el DataFrame.\n",
    "\n",
    "    Returns: \n",
    "    No devuelve nada directamente, pero imprime en la consola la información exploratoria.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Los duplicados que tenemos en el conjunto de datos son: {dataframe.duplicated().sum()}\")\n",
    "    print(\"\\n ..................... \\n\")\n",
    "    \n",
    "    \n",
    "    # generamos un DataFrame para los valores nulos\n",
    "    print(\"Los nulos que tenemos en el conjunto de datos son:\")\n",
    "    df_nulos = pd.DataFrame(dataframe.isnull().sum() / dataframe.shape[0] * 100, columns = [\"%_nulos\"])\n",
    "    display(df_nulos[df_nulos[\"%_nulos\"] > 0])\n",
    "    \n",
    "    print(\"\\n ..................... \\n\")\n",
    "    print(f\"Los tipos de las columnas son:\")\n",
    "    display(pd.DataFrame(dataframe.dtypes, columns = [\"tipo_dato\"]))\n",
    "    \n",
    "    \n",
    "    print(\"\\n ..................... \\n\")\n",
    "    print(\"Los valores que tenemos para las columnas categóricas son: \")\n",
    "    dataframe_categoricas = dataframe.select_dtypes(include = \"O\")\n",
    "    \n",
    "    for col in dataframe_categoricas.columns:\n",
    "        print(f\"La columna {col.upper()} tiene las siguientes valore únicos:\")\n",
    "        display(pd.DataFrame(dataframe[col].value_counts()).head())    \n",
    "    \n",
    "    # como estamos en un problema de A/B testing y lo que realmente nos importa es comparar entre el grupo de control y el de test, los principales estadísticos los vamos a sacar de cada una de las categorías\n",
    "    \n",
    "    for categoria in dataframe[columna_control].unique():\n",
    "        \n",
    "        dataframe_filtrado = dataframe[dataframe[columna_control] == categoria]\n",
    "    \n",
    "        print(\"\\n ..................... \\n\")\n",
    "        print(f\"Los principales estadísticos de las columnas categóricas para el {categoria.upper()} son: \")\n",
    "        display(dataframe_filtrado.describe(include = \"O\").T)\n",
    "        \n",
    "        print(\"\\n ..................... \\n\")\n",
    "        print(f\"Los principales estadísticos de las columnas numéricas para el {categoria.upper()} son: \")\n",
    "        display(dataframe_filtrado.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear subgrafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear subgráficos\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "\n",
    "# Gráfico 1: Tasa de Clicks (CTR)\n",
    "sns.barplot(x=\"campaign_name\", y=\"CTR\", data=df, ax=axes[0])\n",
    "axes[0].set_title(\"Tasa de Clicks\")\n",
    "\n",
    "# Gráfico 2: Tasa de Conversión (CR)\n",
    "sns.barplot(x=\"campaign_name\", y=\"CR\", data=df, ax=axes[1])\n",
    "axes[1].set_title(\"Tasa de Conversión\")\n",
    "\n",
    "# Gráfico 3: Costo por Adquisición (CPA)\n",
    "sns.barplot(x=\"campaign_name\", y=\"CPA\", data=df, ax=axes[2])\n",
    "axes[2].set_title(\"Coste por Adquisición\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordemos cuántos nulos tenemos y en que porcentaje están para decidir correctamente que método de imputación usamos:\n",
    "# solo tenemos nulos en variables numéricas, por lo que solo lo haremos para este tipo de variables\n",
    "nulos_esta_num = df[df.columns[df.isnull().any()]].select_dtypes(include = np.number).columns\n",
    "print(\"Las columnas numéricas que tienen nulos son : \\n \")\n",
    "print(nulos_esta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como en todos los casos tenemos menos de un 5% de nulos, optaremos por reemplazar por la media o la mediana, para elegir la mejor métrica hagamos un 'decribe()' para decidir que estadístico es mejor\n",
    "df[nulos_esta_num].describe().T.loc[:, [\"mean\", \"50%\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazamos los valores nulos\n",
    "for columna in nulos_esta_num:\n",
    "    mediana = df[columna].median()\n",
    "    df[columna] = df[columna].fillna(mediana)\n",
    "    \n",
    "# comprobamos que ya no queden valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas estadísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalidad from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que hacemos es crear una función para testar la normalidad de los datos\n",
    "def normalidad(dataframe, columna):\n",
    "    \"\"\"\n",
    "    Evalúa la normalidad de una columna de datos de un DataFrame utilizando la prueba de Shapiro-Wilk.\n",
    "\n",
    "    Parámetros:\n",
    "        dataframe (DataFrame): El DataFrame que contiene los datos.\n",
    "        columna (str): El nombre de la columna en el DataFrame que se va a evaluar para la normalidad.\n",
    "\n",
    "    Returns:\n",
    "        None: Imprime un mensaje indicando si los datos siguen o no una distribución normal.\n",
    "    \"\"\"\n",
    "\n",
    "    statistic, p_value = stats.shapiro(dataframe[columna])\n",
    "    if p_value > 0.05:\n",
    "        print(f\"Para la columna {columna} los datos siguen una distribución normal.\")\n",
    "    else:\n",
    "        print(f\"Para la columna {columna} los datos no siguen una distribución normal.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = ['CTR', 'CR', 'CPA']\n",
    "\n",
    "for metrica in metricas:\n",
    "    normalidad(df ,metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## varianzas from scipy.stats import levene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def homogeneidad (dataframe, columna, columna_metrica):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evalúa la homogeneidad de las varianzas entre grupos para una métrica específica en un DataFrame dado.\n",
    "\n",
    "    Parámetros:\n",
    "    - dataframe (DataFrame): El DataFrame que contiene los datos.\n",
    "    - columna (str): El nombre de la columna que se utilizará para dividir los datos en grupos.\n",
    "    - columna_metrica (str): El nombre de la columna que se utilizará para evaluar la homogeneidad de las varianzas.\n",
    "\n",
    "    Returns:\n",
    "    No devuelve nada directamente, pero imprime en la consola si las varianzas son homogéneas o no entre los grupos.\n",
    "    Se utiliza la prueba de Levene para evaluar la homogeneidad de las varianzas. Si el valor p resultante es mayor que 0.05,\n",
    "    se concluye que las varianzas son homogéneas; de lo contrario, se concluye que las varianzas no son homogéneas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # lo primero que tenemos que hacer es crear tantos conjuntos de datos para cada una de las categorías que tenemos, Control Campaign y Test Campaign\n",
    "    valores_evaluar = []\n",
    "    \n",
    "    for valor in dataframe[columna].unique():\n",
    "        valores_evaluar.append(dataframe[dataframe[columna]== valor][columna_metrica])\n",
    "\n",
    "    statistic, p_value = stats.levene(*valores_evaluar)\n",
    "    if p_value > 0.05:\n",
    "        print(f\"Para la métrica {columna_metrica} las varianzas son homogéneas entre grupos.\")\n",
    "    else:\n",
    "        print(f\"Para la métrica {columna_metrica}, las varianzas no son homogéneas entre grupos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = ['CTR', 'CR', 'CPA']\n",
    "\n",
    "for metrica in metricas:\n",
    "    homogeneidad(df ,'campaign_name', metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## independencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas numéricas del DataFrame\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.show()\n",
    "\n",
    "# Realizar la prueba de chi-cuadrado para evaluar la independencia de dos variables categóricas\n",
    "contingency_table = pd.crosstab(df['campaign_name'], df['date'])\n",
    "chi2, p_chi2, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"Prueba de Chi-cuadrado - p-valor: {p_chi2}\")\n",
    "\n",
    "# Realizar una prueba t para comparar las medias de dos grupos (por ejemplo, Control vs. Test)\n",
    "control_group = df[df['campaign_name'] == 'Control Campaign']\n",
    "test_group = df[df['campaign_name'] == 'Test Campaign']\n",
    "t_stat, p_ttest = ttest_ind(control_group['CTR'], test_group['CTR'])\n",
    "print(f\"Prueba t para CTR entre Control y Test - p-valor: {p_ttest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test m with from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a crear una función para calcular este test y ver si hay diferencias entre los grupos de estudio\n",
    "\n",
    "def test_man_whitney(dataframe, columnas_metricas, grupo_control, grupo_test, columna_grupos = \"campaign_name\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Realiza la prueba de Mann-Whitney U para comparar las medianas de las métricas entre dos grupos en un DataFrame dado.\n",
    "\n",
    "    Parámetros:\n",
    "    - dataframe (DataFrame): El DataFrame que contiene los datos.\n",
    "    - columnas_metricas (list): Una lista de nombres de columnas que representan las métricas a comparar entre los grupos.\n",
    "    - grupo_control (str): El nombre del grupo de control en la columna especificada por columna_grupos.\n",
    "    - grupo_test (str): El nombre del grupo de test en la columna especificada por columna_grupos.\n",
    "    - columna_grupos (str): El nombre de la columna que contiene la información de los grupos. Por defecto, \"campaign_name\".\n",
    "\n",
    "    Returns \n",
    "    No devuelve nada directamente, pero imprime en la consola si las medianas son diferentes o iguales para cada métrica.\n",
    "    Se utiliza la prueba de Mann-Whitney U para evaluar si hay diferencias significativas entre los grupos.\n",
    "    \"\"\"\n",
    "    # filtramos el DataFrame para quedarnos solo con los datos de control\n",
    "    control = dataframe[dataframe[columna_grupos] == grupo_control]\n",
    "    \n",
    "    # filtramos el DataFrame para quedarnos solo con los datos de control\n",
    "    test = dataframe[dataframe[columna_grupos] == grupo_test]\n",
    "    \n",
    "    \n",
    "    # iteramos por las columnas de las metricas para ver si para cada una de ellas hay diferencias entre los grupos\n",
    "    for metrica in columnas_metricas:\n",
    "        \n",
    "        # filtrams el conjunto de datos para quedarnos solo con la columna de la metrica que nos interesa\n",
    "        metrica_control = control[metrica]\n",
    "        metrica_test = test[metrica]\n",
    "        \n",
    "        # aplicamos el estadístico\n",
    "        u_statistic, p_value = stats.mannwhitneyu(metrica_control, metrica_test)\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"Para la métrica {metrica}, las medianas son diferentes.\")\n",
    "        else:\n",
    "            print(f\"Para la métrica {metrica}, las medianas son iguales.\")\n",
    "            \n",
    "    \n",
    "\n",
    "## llamamos a la función\n",
    "test_man_whitney(df, metricas, \"Control Campaign\", \"Test Campaign\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
